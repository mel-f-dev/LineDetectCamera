{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선 따기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import torch\n",
    "import getopt    # 명령행 옵션 정의, 설정한 변수 값으로 할당\n",
    "import math\n",
    "import numpy\n",
    "import os\n",
    "import PIL    # Python Image Library\n",
    "import PIL.Image\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(int(str('').join(torch.__version__.split('.')[0:3]).split('+')[0]) >= 41) # requires at least pytorch version 0.4.1\n",
    "\n",
    "torch.set_grad_enabled(False) # make sure to not compute gradients for computational performance\n",
    "\n",
    "torch.backends.cudnn.enabled = True # make sure to use cudnn for computational performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments_strModel = 'bsds500'\n",
    "arguments_strIn = 'image/eiffel.jpg'    # 변환할 파일\n",
    "arguments_strOut = 'HED_eiffel.jpg'        # 변환해서 저장할 파일 이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Network, self).__init__()\n",
    "\n",
    "\t\tself.moduleVggOne = torch.nn.Sequential(\n",
    "\t\t\ttorch.nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "\t\t\ttorch.nn.ReLU(inplace=False),\n",
    "\t\t\ttorch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "\t\t\ttorch.nn.ReLU(inplace=False)\n",
    "\t\t)\n",
    "\n",
    "\t\tself.moduleVggTwo = torch.nn.Sequential(\n",
    "\t\t\ttorch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\ttorch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "\t\t\ttorch.nn.ReLU(inplace=False),\n",
    "\t\t\ttorch.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "\t\t\ttorch.nn.ReLU(inplace=False)\n",
    "\t\t)\n",
    "\n",
    "\t\tself.moduleVggThr = torch.nn.Sequential(\n",
    "\t\t\ttorch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\ttorch.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "\t\t\ttorch.nn.ReLU(inplace=False),\n",
    "\t\t\ttorch.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "\t\t\ttorch.nn.ReLU(inplace=False),\n",
    "\t\t\ttorch.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "\t\t\ttorch.nn.ReLU(inplace=False)\n",
    "\t\t)\n",
    "\n",
    "\t\tself.moduleVggFou = torch.nn.Sequential(\n",
    "\t\t\ttorch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\ttorch.nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "\t\t\ttorch.nn.ReLU(inplace=False),\n",
    "\t\t\ttorch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "\t\t\ttorch.nn.ReLU(inplace=False),\n",
    "\t\t\ttorch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "\t\t\ttorch.nn.ReLU(inplace=False)\n",
    "\t\t)\n",
    "\n",
    "\t\tself.moduleVggFiv = torch.nn.Sequential(\n",
    "\t\t\ttorch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\ttorch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "\t\t\ttorch.nn.ReLU(inplace=False),\n",
    "\t\t\ttorch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "\t\t\ttorch.nn.ReLU(inplace=False),\n",
    "\t\t\ttorch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "\t\t\ttorch.nn.ReLU(inplace=False)\n",
    "\t\t)\n",
    "\n",
    "\t\tself.moduleScoreOne = torch.nn.Conv2d(in_channels=64, out_channels=1, kernel_size=1, stride=1, padding=0)\n",
    "\t\tself.moduleScoreTwo = torch.nn.Conv2d(in_channels=128, out_channels=1, kernel_size=1, stride=1, padding=0)\n",
    "\t\tself.moduleScoreThr = torch.nn.Conv2d(in_channels=256, out_channels=1, kernel_size=1, stride=1, padding=0)\n",
    "\t\tself.moduleScoreFou = torch.nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1, stride=1, padding=0)\n",
    "\t\tself.moduleScoreFiv = torch.nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "\t\tself.moduleCombine = torch.nn.Sequential(\n",
    "\t\t\ttorch.nn.Conv2d(in_channels=5, out_channels=1, kernel_size=1, stride=1, padding=0),\n",
    "\t\t\ttorch.nn.Sigmoid()\n",
    "\t\t)\n",
    "\n",
    "\t\tself.load_state_dict(torch.load('./network-' + arguments_strModel + '.pytorch'))\n",
    "\t# end\n",
    "\n",
    "\tdef forward(self, tensorInput):\n",
    "\t\ttensorBlue = (tensorInput[:, 0:1, :, :] * 255.0) - 104.00698793\n",
    "\t\ttensorGreen = (tensorInput[:, 1:2, :, :] * 255.0) - 116.66876762\n",
    "\t\ttensorRed = (tensorInput[:, 2:3, :, :] * 255.0) - 122.67891434\n",
    "\n",
    "\t\ttensorInput = torch.cat([ tensorBlue, tensorGreen, tensorRed ], 1)\n",
    "\n",
    "\t\ttensorVggOne = self.moduleVggOne(tensorInput)\n",
    "\t\ttensorVggTwo = self.moduleVggTwo(tensorVggOne)\n",
    "\t\ttensorVggThr = self.moduleVggThr(tensorVggTwo)\n",
    "\t\ttensorVggFou = self.moduleVggFou(tensorVggThr)\n",
    "\t\ttensorVggFiv = self.moduleVggFiv(tensorVggFou)\n",
    "\n",
    "\t\ttensorScoreOne = self.moduleScoreOne(tensorVggOne)\n",
    "\t\ttensorScoreTwo = self.moduleScoreTwo(tensorVggTwo)\n",
    "\t\ttensorScoreThr = self.moduleScoreThr(tensorVggThr)\n",
    "\t\ttensorScoreFou = self.moduleScoreFou(tensorVggFou)\n",
    "\t\ttensorScoreFiv = self.moduleScoreFiv(tensorVggFiv)\n",
    "\n",
    "\t\ttensorScoreOne = torch.nn.functional.interpolate(input=tensorScoreOne, size=(tensorInput.size(2), tensorInput.size(3)), mode='bilinear', align_corners=False)\n",
    "\t\ttensorScoreTwo = torch.nn.functional.interpolate(input=tensorScoreTwo, size=(tensorInput.size(2), tensorInput.size(3)), mode='bilinear', align_corners=False)\n",
    "\t\ttensorScoreThr = torch.nn.functional.interpolate(input=tensorScoreThr, size=(tensorInput.size(2), tensorInput.size(3)), mode='bilinear', align_corners=False)\n",
    "\t\ttensorScoreFou = torch.nn.functional.interpolate(input=tensorScoreFou, size=(tensorInput.size(2), tensorInput.size(3)), mode='bilinear', align_corners=False)\n",
    "\t\ttensorScoreFiv = torch.nn.functional.interpolate(input=tensorScoreFiv, size=(tensorInput.size(2), tensorInput.size(3)), mode='bilinear', align_corners=False)\n",
    "\n",
    "\t\treturn self.moduleCombine(torch.cat([ tensorScoreOne, tensorScoreTwo, tensorScoreThr, tensorScoreFou, tensorScoreFiv ], 1))\n",
    "\t# end\n",
    "# end\n",
    "\n",
    "moduleNetwork = Network().cuda().eval()\n",
    "\n",
    "##########################################################\n",
    "\n",
    "def estimate(tensorInput):\n",
    "\tintWidth = tensorInput.size(2)\n",
    "\tintHeight = tensorInput.size(1)\n",
    "\n",
    "# \tassert(intWidth == 1800) # remember that there is no guarantee for correctness, comment this line out if you acknowledge this and want to continue\n",
    "# \tassert(intHeight == 1200) # remember that there is no guarantee for correctness, comment this line out if you acknowledge this and want to continue\n",
    "\n",
    "\treturn moduleNetwork(tensorInput.cuda().view(1, 3, intHeight, intWidth))[0, :, :, :].cpu()\n",
    "# end\n",
    "\n",
    "##########################################################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\ttensorInput = torch.FloatTensor(numpy.array(PIL.Image.open(arguments_strIn))[:, :, ::-1].transpose(2, 0, 1).astype(numpy.float32) * (1.0 / 255.0))\n",
    "\n",
    "\ttensorOutput = estimate(tensorInput)\n",
    "\n",
    "\tPIL.Image.fromarray((tensorOutput.clamp(0.0, 1.0).numpy().transpose(1, 2, 0)[:, :, 0] * 255.0).astype(numpy.uint8)).save(arguments_strOut)\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라인만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame= Image.open('images/frame_tour.jpg')    \n",
    "frame_invert = ImageOps.invert(frame).convert('L')\n",
    "#edges_invert = ImageOps.invert(edges).convert('L')\n",
    "\n",
    "\n",
    "im_rgb = Image.open('images/night.jpg').resize(frame_invert.size)    # 배경으로 할 파일\n",
    "#im_rgb = Image.open('lena.jpg').resize(edges_invert.size)\n",
    "\n",
    "im_rgb.putalpha(frame_invert)\n",
    "#im_rgb.putalpha(edges_invert)\n",
    "im_rgb.save('just_line_tour.png')    # 선만 추출해서 저장할 파일 이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 흰배경\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "\n",
    "img = cv2.imread('HED_firenze.jpg',0)    # 프레임으로 만들 파일\n",
    "cv2.imwrite(\"frame/frame_white_firenze.png\", cv2.Canny(img, 50, 300))    # Canny로 프레임 저장\n",
    "frame= Image.open('frame/frame_white_firenze.png')    # 프레임 열기\n",
    "im_rgb = Image.open('image/black_back.jpg').resize(frame.size)    # 배경으로 할 사진\n",
    "\n",
    "im_rgb.putalpha(frame)\n",
    "im_rgb.save('HED_Canny_firenze.png')    # 저장할 파일 이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
